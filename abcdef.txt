1. Initial setup: Set up a virtual machine (VM) with a fresh installation of Ubuntu 20.04.
2. Installing hadoop dependencies, setting up the environment: Hadoop requires Java 8
or 11 install default-jdk by executing the following command:
 $ sudo apt install default-jdk
The default JDK in Ubuntu 20.04 is 11, but you can also install JDK 11 explicitly by
installing the openjdk-11-jdk package, as follows:
 $ sudo apt install openjdk-11-jdk
3. Confirm that Java 11 is installed:
 $ java -version
openjdk version "11.0.11" 2021-04-20
OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.20.04)
OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.20.04, mixed mode,
sharing).
4. Now set up the environment variables: Hadoop requires JAVA_HOME to be set, and
variable HADOOP_HOME. Append the following lines to $HOME/.profile:
 export JAVA_HOME="/usr/lib/jvm/java-11-openjdk-amd64"
 export HADOOP_HOME="/opt/hadoop-3.3.1"
(or)
 $ echo"export JAVA_HOME=\"/usr/lib/jvm/java-11-openjdk-amd64\"" >>
HOME/.profile
 $ echo "export HADOOP_HOME=\"/opt/hadoop-3.3.1\"" >> $HOME/.profile
5. Source the file to apply the changes:
 $ source $HOME/.profile
6. Confirm that the environment variables are correctly set:
 $ echo $JAVA_HOME
/usr/lib/jvm/java-11-openjdk-amd64
 $ echo $HADOOP_HOME
/opt/hadoop-3.3.1
 listing the files included in the openjdk-11-jdk package using dpkg:
$ dpkg -L openjdk-11-jdk
7. Installing Hadoop 3.3.1
The de-facto way of installing Hadoop in 2021 is (still) directly fetching the compressed
tarball from upstream. Fetch the upstream tarball for Hadoop 3.3.1 using wget:
$ wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz

CS8711-Cloud Computing Laboratory Department of CSE 2023-2024

41

8. Unpack the tarball:
 $ tar xvf hadoop-3.3.1.tar.gz
9. Now copy it to an appropriate location, e.g. $HADOOP_HOME:
 $ sudo cp -r hadoop-3.3.1 "$HADOOP_HOME"
This copies and places the Hadoop program files under /opt, which is where manually
installed software should be placed as dictated by the FHS.
10. Hadoop binaries are located under $HADOOP_HOME/bin. Add that to our PATH:
 $ echo "export PATH=\"\$PATH:\$HADOOP_HOME/bin\"" >>
$HOME/.profile
 $ source $HOME/.profile
If you did everything correctly, the hadoop command should now be available and print
usage instructions:
 $ hadoop
11. Fetch our text sample:
$wget
https://raw.githubusercontent.com/ErikSchierboom/sentencegenerator/master/samples
/the-king-james-bible.txt
Now create an input directory and place the text sample there:
 $ mkdir input
 $ mv the-king-james-bible.txt input
My KJB copy is 4.2 megabytes in size:
12. $ ls -lh input
total 4.2M
-rw-rw-r-- 1 ubuntu ubuntu 4.2M AUG 14 10:20 the-king-james-bible.txt
13. Finally we invoke the WordCount MapReduce program with input
directory input and output directory output:
 $ hadoop jar
"$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.
3.1.jar" wordcount input output
14. Confirm that the output has been successfully generated:
 $ ls -lh output
total 336K
-rw-r--r-- 1 ubuntu ubuntu 0 AUG 14 10:26 _SUCCESS
-rw-r--r-- 1 ubuntu ubuntu 334K AUG 14 10:26 part-r-00000
So our output fits in a single block (output/part-r-00000) as expected.
15. Finally, let's take the last 10 lines of our output (or the first 10 lines, or whatever):
$ tail output/part-r-00000
youth 7
youth 8
youth 2
youthful 1
youths 1
youths 1

CS8711-Cloud Computing Laboratory Department of CSE 2023-2024

42

zeal 13
zeal 3
zealous 8
zealously 2
16. Remove the output directory:
 $ rm -rf output
